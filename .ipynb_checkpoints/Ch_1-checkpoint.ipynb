{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c341dc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 19:31:33.051429: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-14 19:31:33.051451: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-14 19:31:34.261119: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-14 19:31:34.261275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-14 19:31:34.261654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-14 19:31:34.261998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:26:00.0 name: NVIDIA GeForce GTX 1660 Ti computeCapability: 7.5\n",
      "coreClock: 1.875GHz coreCount: 24 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 268.26GiB/s\n",
      "2023-01-14 19:31:34.262069: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-14 19:31:34.262110: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-14 19:31:34.262149: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-14 19:31:34.262178: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-14 19:31:34.262197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-14 19:31:34.262215: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-01-14 19:31:34.262249: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-14 19:31:34.262287: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-14 19:31:34.262294: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9fe474",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cf56e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Hello World!\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7525488c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World\n"
     ]
    }
   ],
   "source": [
    "token = doc[1]\n",
    "print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c58c102c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World!\n"
     ]
    }
   ],
   "source": [
    "span = doc[1:3]\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "341f4e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index        [0, 1, 2, 3, 4]\n",
      "Text:        ['It', 'costs', '$', '5', '.']\n",
      "is_alpha:    [True, True, False, False, False]\n",
      "is_punct:    [False, False, False, False, True]\n",
      "like_num:    [False, False, False, True, False]\n"
     ]
    }
   ],
   "source": [
    "# Lexical attributes\n",
    "doc = nlp(\"It costs $5.\")\n",
    "print(\"Index       \", [token.i for token in doc])\n",
    "print(\"Text:       \", [token.text for token in doc])\n",
    "print(\"is_alpha:   \", [token.is_alpha for token in doc])\n",
    "print(\"is_punct:   \", [token.is_punct for token in doc])\n",
    "print(\"like_num:   \", [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b046d900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index        [0, 1, 2, 3, 4]\n",
      "Text:        ['My', 'email', 'adress', 'is', 'max.mustermann@web.de']\n",
      "is_alpha:    [True, True, True, True, False]\n",
      "is_punct:    [False, False, False, False, False]\n",
      "like_num:    [False, False, False, False, False]\n",
      "like_email:  [False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "# Lexical attributes\n",
    "doc = nlp(\"My email adress is max.mustermann@web.de\")\n",
    "print(\"Index       \", [token.i for token in doc])\n",
    "print(\"Text:       \", [token.text for token in doc])\n",
    "print(\"is_alpha:   \", [token.is_alpha for token in doc])\n",
    "print(\"is_punct:   \", [token.is_punct for token in doc])\n",
    "print(\"like_num:   \", [token.like_num for token in doc])\n",
    "print(\"like_email: \", [token.like_email for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f777a629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage found: 5.34\n",
      "Percentage found: 3.34\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The inflation rate is 5.34%. That is 2 percentage points higher than last month (3.34%)\")\n",
    "for token in doc:\n",
    "    if token.like_num:\n",
    "        next_token = doc[token.i + 1]\n",
    "        if next_token.text == \"%\":\n",
    "            print(\"Percentage found:\", token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdcd851",
   "metadata": {},
   "source": [
    "## Trained Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44fd7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b66697ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON\n",
      "ate VERB\n",
      "the DET\n",
      "pizza NOUN\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"She ate the pizza\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "501c2cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON nsubj ate\n",
      "ate VERB ROOT ate\n",
      "the DET det pizza\n",
      "pizza NOUN dobj ate\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08e3e61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d75b4d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries, cities, states\n",
      "noun, proper singular\n",
      "Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "print(spacy.explain(\"GPE\"))\n",
    "print(spacy.explain(\"NNP\"))\n",
    "print(spacy.explain(\"ORG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2508e0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "determiner\n"
     ]
    }
   ],
   "source": [
    "print(spacy.explain(\"det\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f93200fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "direct object\n"
     ]
    }
   ],
   "source": [
    "print(spacy.explain(\"dobj\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951c8437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
